{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DigitRec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5yvakKl2SOK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyNIU2ua3lSI"
      },
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKGR_zP3lUZ"
      },
      "source": [
        "train_images=pd.read_csv('train.csv')\n",
        "test_images=pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyAIs26T3lXO"
      },
      "source": [
        "train_target=train_images['label']\n",
        "train_images=train_images.drop(['label'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrX73ZIz3vWC"
      },
      "source": [
        "###Normalize and Reshape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh2EP3Na3lZp"
      },
      "source": [
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0\n",
        "\n",
        "train_images=train_images.values.reshape(-1, 1, 28,28)\n",
        "test_images=test_images.values.reshape(-1,1, 28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhSVkDjo32TS"
      },
      "source": [
        "###Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlPxrFyG3lb_"
      },
      "source": [
        "class MNISTDataset(Dataset):\n",
        "  def __init__(self, x_train, y_train, mode):\n",
        "    self.x_train=x_train\n",
        "    self.y_train=y_train\n",
        "    self.mode=mode\n",
        "  def __len__(self, ):\n",
        "    return len(self.x_train)\n",
        "  def __getitem__(self, index):\n",
        "    if self.mode=='test':\n",
        "      return self.x_train[index]\n",
        "    else:\n",
        "      return self.x_train[index], self.y_train[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmHhMxSi4BKC"
      },
      "source": [
        "###CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxpCcjrL3leS"
      },
      "source": [
        "class DigitRecognize(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2, stride=1),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.conv2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv3=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=2, stride=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.conv4=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv5=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=2, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.dropOut=nn.Dropout2d(0.33)\n",
        "    self.fc1=nn.Linear(1600, 1000)\n",
        "    self.dropOut_2=nn.Dropout()\n",
        "    self.fc2=nn.Linear(1000, 10)\n",
        "  def forward(self, x):\n",
        "    x=torch.tensor(x, dtype=torch.float32)\n",
        "    x=self.conv1(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.dropOut(x)\n",
        "    x=self.conv4(x)\n",
        "    x=self.conv5(x)\n",
        "    x=self.dropOut(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x=self.fc1(x)\n",
        "    x=self.dropOut_2(x)\n",
        "    x=self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "330LysoN4Rfc"
      },
      "source": [
        "###Train Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSETHS8M3lg5"
      },
      "source": [
        "def train_epoch(model, train_data, optimizer, criterion):\n",
        "  running_loss=0.0\n",
        "  running_correct=0\n",
        "  running_total=0\n",
        "  model.train()\n",
        "  for x_batch, y_batch in train_data:\n",
        "    y_batch=y_batch.type(torch.LongTensor)\n",
        "    x_batch=x_batch.to(DEVICE)\n",
        "    y_batch=y_batch.to(DEVICE)\n",
        "    output=model(x_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss=criterion(output, y_batch)\n",
        "    preds=torch.argmax(output, 1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss*x_batch.size(0)\n",
        "    running_correct+=(preds==y_batch).sum().item()\n",
        "    running_total+=x_batch.size(0)\n",
        "  train_loss=running_loss/running_total\n",
        "  train_acc=running_correct/running_total\n",
        "  return train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPlqpo-4NEJ"
      },
      "source": [
        "###Loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLirkk6K3ljO"
      },
      "source": [
        "def val_epoch(model, test_data, criterion):\n",
        "  running_loss=0.0\n",
        "  running_correct=0\n",
        "  running_total=0\n",
        "  with torch.no_grad():\n",
        "    for x_batch, y_batch in test_data:\n",
        "      y_batch=y_batch.type(torch.LongTensor)\n",
        "      x_batch=x_batch.to(DEVICE)\n",
        "      y_batch=y_batch.to(DEVICE)\n",
        "      model.eval()\n",
        "      output=model(x_batch)\n",
        "      loss=criterion(output, y_batch)\n",
        "      preds=torch.argmax(output, 1)\n",
        "      running_loss+=loss*x_batch.size(0)\n",
        "      running_correct+=(preds==y_batch).sum().item()\n",
        "      running_total+=x_batch.size(0)\n",
        "  test_loss=running_loss/running_total\n",
        "  test_acc=running_correct/running_total\n",
        "  return test_loss, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFmelduM4YhU"
      },
      "source": [
        "###Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9AynHi_3llw"
      },
      "source": [
        "def train(model,train_dataset, batch_size, epochs):\n",
        "  max_acc=0\n",
        "  history=[]\n",
        "  with tqdm(desc=\"epochs\", total=epochs) as tbar:\n",
        "      for i in range(epochs):\n",
        "        if i%10==0:\n",
        "          train_data, test_data=train_test_split(train_dataset, test_size=0.1)\n",
        "          test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "          train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "            #Shuffle data every 10 epoch\n",
        "        criterion=nn.CrossEntropyLoss()\n",
        "        optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        train_loss, train_acc=train_epoch(model, train_loader, optimizer, criterion)\n",
        "        test_loss, test_acc=val_epoch(model, test_loader, criterion)\n",
        "        print()\n",
        "        if test_acc>max_acc:\n",
        "          max_acc=test_acc\n",
        "          torch.save(model.state_dict(), \"MNISTModel\")\n",
        "          print(f'Model with accuracy: {test_acc} is saved')\n",
        "        print(\"Loss:\", test_loss.item())\n",
        "        print(\"Accuracy:\",test_acc)\n",
        "        history.append((train_loss, train_acc,  test_loss, test_acc))\n",
        "        tbar.update(1)\n",
        "        print(f'Epoch {i+1} train_loss: {train_loss:.3}  val_loss: {test_loss:.3} train_acc: {train_acc:.5} val_acc: {test_acc:.5}')\n",
        "  return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa88dKUz3loe"
      },
      "source": [
        "model=DigitRecognize(10).to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Ed7hHq3lqe"
      },
      "source": [
        "train_dataset=MNISTDataset(train_images, train_target, 'train')\n",
        "test_dataset=MNISTDataset(test_images,None , 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AG3iLUP3lsS"
      },
      "source": [
        "history=train(model,train_dataset, 128, 100) #You can try to change count of epochs and batch size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoGjnsf74kSu"
      },
      "source": [
        "train_loss, train_acc, test_loss, test_acc=zip(*history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO3GSGCi4kU_"
      },
      "source": [
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(train_loss, label=\"Train loss\")\n",
        "plt.plot(test_loss, label=\"Test loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjM2mq5v4kW5"
      },
      "source": [
        "plt.figure(figsize=(15,9))\n",
        "plt.plot(train_acc, label=\"Train accuracy\")\n",
        "plt.plot(test_acc, label=\"Test accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtVtsfll4rPF"
      },
      "source": [
        "def predict(model, test_data,batch_size):\n",
        "  logits=[]\n",
        "  test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for x_batch in test_loader:\n",
        "      x_batch=x_batch.to(DEVICE)\n",
        "      outputs=model(x_batch).cpu()\n",
        "      preds=torch.argmax(outputs, 1)\n",
        "      for i in preds:\n",
        "        logits.append(i.item())\n",
        "  return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x76pj1N4rQ7"
      },
      "source": [
        "load_model=DigitRecognize(10).to(DEVICE)\n",
        "load_model.load_state_dict(torch.load(\"MNISTModel\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n8KH3gX4rVQ"
      },
      "source": [
        "predict_res=predict(load_model,test_dataset,64)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}