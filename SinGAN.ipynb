{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SinGAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_teh4A4skGRT"
      },
      "source": [
        "# SinGAN\n",
        "\n",
        "[Official SinGAN Repository](https://github.com/tamarott/SinGAN)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44sUVaB4mWL4"
      },
      "source": [
        "#requires older version of PyTorch.\n",
        "!pip3 install torch==1.4.0\n",
        "!pip install torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF-QL9B0z7sl"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/mswang12/SinGAN.git\n",
        "%cd /content/SinGAN\n",
        "!git checkout experimental\n",
        "%cd /content/SinGAN/Input/Images/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTHAHNbnL5W6"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print('original image')\n",
        "original_img_path = '/content/SinGAN/Input/Images/HRImage.png'\n",
        "img = cv2.imread(original_img_path)\n",
        "print(img.shape)\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('original image')\n",
        "original_img_path = '/content/SinGAN/Input/Images/LRImage.png'\n",
        "img2 = cv2.imread(original_img_path)\n",
        "new_img = cv2.resize(img2, (img.shape[1], img.shape[0]))\n",
        "print(new_img.shape)\n",
        "cv2_imshow(new_img)\n",
        "cv2.imwrite('/content/SinGAN/Input/Images/tree_resized.png', new_img)\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nUJqiIxbzs6"
      },
      "source": [
        "# Let's train SinGAN here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8KF6KxWcFpB"
      },
      "source": [
        "#training.py\n",
        "def train_single_scale2(netD,netG,reals,Gs,Zs,in_s,NoiseAmp,opt,centers=None):\n",
        "    print('placeholder')\n",
        "    real = reals[len(Gs)]\n",
        "    opt.nzx = real.shape[2]#+(opt.ker_size-1)*(opt.num_layer)\n",
        "    opt.nzy = real.shape[3]#+(opt.ker_size-1)*(opt.num_layer)\n",
        "    opt.receptive_field = opt.ker_size + ((opt.ker_size-1)*(opt.num_layer-1))*opt.stride\n",
        "    pad_noise = int(((opt.ker_size - 1) * opt.num_layer) / 2)\n",
        "    pad_image = int(((opt.ker_size - 1) * opt.num_layer) / 2)\n",
        "    if opt.mode == 'animation_train':\n",
        "        opt.nzx = real.shape[2]+(opt.ker_size-1)*(opt.num_layer)\n",
        "        opt.nzy = real.shape[3]+(opt.ker_size-1)*(opt.num_layer)\n",
        "        pad_noise = 0\n",
        "    m_noise = nn.ZeroPad2d(int(pad_noise))\n",
        "    m_image = nn.ZeroPad2d(int(pad_image))\n",
        "\n",
        "    alpha = opt.alpha\n",
        "\n",
        "    fixed_noise = functions.generate_noise([opt.nc_z,opt.nzx,opt.nzy],device=opt.device)\n",
        "    z_opt = torch.full(fixed_noise.shape, 0, device=opt.device)\n",
        "    z_opt = m_noise(z_opt)\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lr_d, betas=(opt.beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lr_g, betas=(opt.beta1, 0.999))\n",
        "    schedulerD = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerD,milestones=[1600],gamma=opt.gamma)\n",
        "    schedulerG = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerG,milestones=[1600],gamma=opt.gamma)\n",
        "\n",
        "    errD2plot = []\n",
        "    errG2plot = []\n",
        "    D_real2plot = []\n",
        "    D_fake2plot = []\n",
        "    z_opt2plot = []\n",
        "\n",
        "\n",
        " \n",
        "    #for epoch in range(int(opt.niter / 2)):\n",
        "    for epoch in range(5):\n",
        "        if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "            z_opt = functions.generate_noise([1,opt.nzx,opt.nzy], device=opt.device)\n",
        "            z_opt = m_noise(z_opt.expand(1,3,opt.nzx,opt.nzy))\n",
        "            noise_ = functions.generate_noise([1,opt.nzx,opt.nzy], device=opt.device)\n",
        "            noise_ = m_noise(noise_.expand(1,3,opt.nzx,opt.nzy))\n",
        "        else:\n",
        "            noise_ = functions.generate_noise([opt.nc_z,opt.nzx,opt.nzy], device=opt.device)\n",
        "            noise_ = m_noise(noise_)\n",
        "\n",
        "        # (1) Update D network:\n",
        "\n",
        "        for j in range(int(opt.Dsteps)):\n",
        "            # train with real\n",
        "            netD.zero_grad()\n",
        "\n",
        "            output = netD(real).to(opt.device)\n",
        "            #D_real_map = output.detach()\n",
        "            errD_real = -output.mean()#-a\n",
        "            errD_real.backward(retain_graph=True)\n",
        "            D_x = -errD_real.item()\n",
        "\n",
        "            # train with fake\n",
        "            if (j==0) & (epoch == 0):\n",
        "                if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "                    prev = torch.full([1,opt.nc_z,opt.nzx,opt.nzy], 0, device=opt.device)\n",
        "                    in_s = prev\n",
        "                    prev = m_image(prev)\n",
        "                    z_prev = torch.full([1,opt.nc_z,opt.nzx,opt.nzy], 0, device=opt.device)\n",
        "                    z_prev = m_noise(z_prev)\n",
        "                    opt.noise_amp = 1\n",
        "                elif opt.mode == 'SR_train':\n",
        "                    z_prev = in_s\n",
        "                    criterion = nn.MSELoss()\n",
        "                    RMSE = torch.sqrt(criterion(real, z_prev))\n",
        "                    opt.noise_amp = opt.noise_amp_init * RMSE\n",
        "                    z_prev = m_image(z_prev)\n",
        "                    prev = z_prev\n",
        "                else:\n",
        "                    prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rand',m_noise,m_image,opt)\n",
        "                    prev = m_image(prev)\n",
        "                    z_prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rec',m_noise,m_image,opt)\n",
        "                    criterion = nn.MSELoss()\n",
        "                    RMSE = torch.sqrt(criterion(real, z_prev))\n",
        "                    opt.noise_amp = opt.noise_amp_init*RMSE\n",
        "                    z_prev = m_image(z_prev)\n",
        "            else:\n",
        "                prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rand',m_noise,m_image,opt)\n",
        "                prev = m_image(prev)\n",
        "\n",
        "            if opt.mode == 'paint_train':\n",
        "                prev = functions.quant2centers(prev,centers)\n",
        "                plt.imsave('%s/prev.png' % (opt.outf), functions.convert_image_np(prev), vmin=0, vmax=1)\n",
        "\n",
        "            if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "                noise = noise_\n",
        "            else:\n",
        "                noise = opt.noise_amp*noise_+prev\n",
        "\n",
        "            fake = netG(noise.detach(),prev)\n",
        "            output = netD(fake.detach())\n",
        "            # NOTE: netD outputs a tensor. The Discriminator is fully convolution and does not depend on the size of the image.\n",
        "            # An image is real or fake depending on the mean of the output tensor.\n",
        "            # Maybe we can talk about this in our Blog post?\n",
        "            errD_fake = output.mean()\n",
        "            errD_fake.backward(retain_graph=True)\n",
        "            D_G_z = output.mean().item()\n",
        "\n",
        "            gradient_penalty = functions.calc_gradient_penalty(netD, real, fake, opt.lambda_grad, opt.device)\n",
        "            gradient_penalty.backward()\n",
        "\n",
        "            errD = errD_real + errD_fake + gradient_penalty\n",
        "            optimizerD.step()\n",
        "\n",
        "        errD2plot.append(errD.detach())\n",
        "\n",
        "  \n",
        "        # (2) Update G network: \n",
        "\n",
        "        for j in range(opt.Gsteps):\n",
        "            netG.zero_grad()\n",
        "            output = netD(fake)\n",
        "            #D_fake_map = output.detach()\n",
        "            errG = -output.mean()\n",
        "            errG.backward(retain_graph=True)\n",
        "            if alpha!=0:\n",
        "                loss = nn.MSELoss()\n",
        "                if opt.mode == 'paint_train':\n",
        "                    z_prev = functions.quant2centers(z_prev, centers)\n",
        "                    plt.imsave('%s/z_prev.png' % (opt.outf), functions.convert_image_np(z_prev), vmin=0, vmax=1)\n",
        "                Z_opt = opt.noise_amp*z_opt+z_prev\n",
        "                rec_loss = alpha*loss(netG(Z_opt.detach(),z_prev),real)\n",
        "                rec_loss.backward(retain_graph=True)\n",
        "                rec_loss = rec_loss.detach()\n",
        "            else:\n",
        "                Z_opt = z_opt\n",
        "                rec_loss = 0\n",
        "\n",
        "            optimizerG.step()\n",
        "\n",
        "        errG2plot.append(errG.detach()+rec_loss)\n",
        "        D_real2plot.append(D_x)\n",
        "        D_fake2plot.append(D_G_z)\n",
        "        z_opt2plot.append(rec_loss)\n",
        "\n",
        "        if epoch % 25 == 0 or epoch == (opt.niter-1):\n",
        "            print('scale %d:[%d/%d]' % (len(Gs), epoch, opt.niter))\n",
        "\n",
        "        if epoch % 500 == 0 or epoch == (opt.niter-1):\n",
        "            plt.imsave('%s/fake_sample.png' %  (opt.outf), functions.convert_image_np(fake.detach()), vmin=0, vmax=1)\n",
        "            plt.imsave('%s/G(z_opt).png'    % (opt.outf),  functions.convert_image_np(netG(Z_opt.detach(), z_prev).detach()), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/D_fake.png'   % (opt.outf), functions.convert_image_np(D_fake_map))\n",
        "            #plt.imsave('%s/D_real.png'   % (opt.outf), functions.convert_image_np(D_real_map))\n",
        "            #plt.imsave('%s/z_opt.png'    % (opt.outf), functions.convert_image_np(z_opt.detach()), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/prev.png'     %  (opt.outf), functions.convert_image_np(prev), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/noise.png'    %  (opt.outf), functions.convert_image_np(noise), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/z_prev.png'   % (opt.outf), functions.convert_image_np(z_prev), vmin=0, vmax=1)\n",
        "\n",
        "\n",
        "            torch.save(z_opt, '%s/z_opt.pth' % (opt.outf))\n",
        "\n",
        "        schedulerD.step()\n",
        "        schedulerG.step()\n",
        "\n",
        "    functions.save_networks(netG,netD,z_opt,opt)\n",
        "    return z_opt,in_s,netG    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RjmZVv6v6w_"
      },
      "source": [
        "#models.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Sequential):\n",
        "  def __init__(self, in_channel, out_channel, ker_size, padd, stride):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.add_module('conv', nn.Conv2d(in_channel, out_channel, kernel_size=ker_size, stride=stride, padding=padd)),\n",
        "    self.add_module('norm', nn.BatchNorm2d(out_channel)),\n",
        "    self.add_module('LeakyRelu', nn.LeakyReLU(0.2))\n",
        "\n",
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv2d') != -1:\n",
        "    m.weight.data.normal_(0.0, 0.02)\n",
        "  elif classname.find('Norm') != -1:\n",
        "    m.weight.data.normal_(1.0, 0.01)\n",
        "    m.bias.data.fill_(0)\n",
        "\n",
        "class WDiscriminator2(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(WDiscriminator2, self).__init__()\n",
        "        self.is_cuda = torch.cuda.is_available()\n",
        "        N = int(opt.nfc)\n",
        "        self.head = ConvBlock(opt.nc_im,N,opt.ker_size,opt.padd_size,1)\n",
        "        self.body = nn.Sequential()\n",
        "        for i in range(opt.num_layer-2):\n",
        "            N = int(opt.nfc/pow(2,(i+1)))\n",
        "            block = ConvBlock(max(2*N,opt.min_nfc),max(N,opt.min_nfc),opt.ker_size,opt.padd_size,1)\n",
        "            self.body.add_module('block%d'%(i+1),block)\n",
        "        self.tail = nn.Conv2d(max(N,opt.min_nfc),1,kernel_size=opt.ker_size,stride=1,padding=opt.padd_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.head(x)\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        return x\n",
        "\n",
        "class GeneratorConcatSkip2CleanAdd2(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(GeneratorConcatSkip2CleanAdd2, self).__init__()\n",
        "        self.is_cuda = torch.cuda.is_available()\n",
        "        N = opt.nfc\n",
        "        self.head = ConvBlock(opt.nc_im,N,opt.ker_size,opt.padd_size,1) #GenConvTransBlock(opt.nc_z,N,opt.ker_size,opt.padd_size,opt.stride)\n",
        "        self.body = nn.Sequential()\n",
        "        for i in range(opt.num_layer-2):\n",
        "            N = int(opt.nfc/pow(2,(i+1)))\n",
        "            block = ConvBlock(max(2*N,opt.min_nfc),max(N,opt.min_nfc),opt.ker_size,opt.padd_size,1)\n",
        "            self.body.add_module('block%d'%(i+1),block)\n",
        "        self.tail = nn.Sequential(\n",
        "            nn.Conv2d(max(N,opt.min_nfc),opt.nc_im,kernel_size=opt.ker_size,stride =1,padding=opt.padd_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self,x,y):\n",
        "        x = self.head(x)\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        ind = int((y.shape[2]-x.shape[2])/2)\n",
        "        y = y[:,:,ind:(y.shape[2]-ind),ind:(y.shape[3]-ind)]\n",
        "        return x+y\n",
        "\n",
        "class DummyOpt:\n",
        "  def __init__(self):\n",
        "    self.nfc = 32\n",
        "    self.nc_im = 3\n",
        "    self.ker_size = 3\n",
        "    self.padd_size = 1\n",
        "    self.num_layer = 5\n",
        "    self.min_nfc = 3\n",
        "opt_example = DummyOpt()\n",
        "D_example = WDiscriminator2(opt_example)\n",
        "G_example = GeneratorConcatSkip2CleanAdd2(opt_example)\n",
        "\n",
        "print(D_example)\n",
        "print(G_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ermi_FoJtbjp"
      },
      "source": [
        "#functions.py\n",
        "def read_image2(opt):\n",
        "    x = img.imread('%s/%s' % (opt.input_dir,opt.input_name))\n",
        "    x = functions.np2torch(x,opt)\n",
        "    x = x[:,0:3,:,:]\n",
        "\n",
        "    x2 = img.imread('%s/%s' % (opt.input_dir,opt.input_name2))\n",
        "    x2 = functions.np2torch(x2,opt)\n",
        "    x2 = x2[:,0:3,:,:]\n",
        "\n",
        "    array = [x, x2]\n",
        "    return array\n",
        "\n",
        "def train2(opt,Gs,Zs,reals, reals2,NoiseAmp):\n",
        "    array = read_image2(opt)\n",
        "    real_ = array[0]\n",
        "    real_2 = array[1]\n",
        "    in_s = 0\n",
        "    scale_num = 0\n",
        "    real = imresize(real_,opt.scale1,opt)\n",
        "    real2 = imresize(real_2,opt.scale1,opt)\n",
        "    reals = functions.creat_reals_pyramid(real,reals,opt)\n",
        "    reals2 = functions.creat_reals_pyramid(real2,reals2,opt)\n",
        "    nfc_prev = 0\n",
        "\n",
        "    while scale_num<opt.stop_scale+1:\n",
        "        opt.nfc = min(opt.nfc_init * pow(2, math.floor(scale_num / 4)), 128)\n",
        "        opt.min_nfc = min(opt.min_nfc_init * pow(2, math.floor(scale_num / 4)), 128)\n",
        "\n",
        "        opt.out_ = functions.generate_dir2save(opt)\n",
        "        opt.outf = '%s/%d' % (opt.out_,scale_num)\n",
        "        try:\n",
        "            os.makedirs(opt.outf)\n",
        "        except OSError:\n",
        "                pass\n",
        "\n",
        "        #plt.imsave('%s/in.png' %  (opt.out_), functions.convert_image_np(real), vmin=0, vmax=1)\n",
        "        #plt.imsave('%s/original.png' %  (opt.out_), functions.convert_image_np(real_), vmin=0, vmax=1)\n",
        "        plt.imsave('%s/real_scale.png' %  (opt.outf), functions.convert_image_np(reals[scale_num]), vmin=0, vmax=1)\n",
        "\n",
        "        D_curr,G_curr = init_models(opt)\n",
        "        if (nfc_prev==opt.nfc):\n",
        "            G_curr.load_state_dict(torch.load('%s/%d/netG.pth' % (opt.out_,scale_num-1)))\n",
        "            D_curr.load_state_dict(torch.load('%s/%d/netD.pth' % (opt.out_,scale_num-1)))\n",
        "\n",
        "        for j in range(100):\n",
        "            z_curr,in_s,G_curr = train_single_scale2(D_curr,G_curr,reals,Gs,Zs,in_s,NoiseAmp,opt)\n",
        "            z_curr,in_s,G_curr = train_single_scale2(D_curr,G_curr,reals2,Gs,Zs,in_s,NoiseAmp,opt)\n",
        "        \n",
        "\n",
        "        G_curr = functions.reset_grads(G_curr,False)\n",
        "        G_curr.eval()\n",
        "        D_curr = functions.reset_grads(D_curr,False)\n",
        "        D_curr.eval()\n",
        "\n",
        "        Gs.append(G_curr)\n",
        "        Zs.append(z_curr)\n",
        "        NoiseAmp.append(opt.noise_amp)\n",
        "\n",
        "        torch.save(Zs, '%s/Zs.pth' % (opt.out_))\n",
        "        torch.save(Gs, '%s/Gs.pth' % (opt.out_))\n",
        "        torch.save(reals, '%s/reals.pth' % (opt.out_))\n",
        "        torch.save(NoiseAmp, '%s/NoiseAmp.pth' % (opt.out_))\n",
        "\n",
        "        scale_num+=1\n",
        "        nfc_prev = opt.nfc\n",
        "        del D_curr,G_curr\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-tLVSDgfueV"
      },
      "source": [
        "%cd /content/SinGAN/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jpfpY2_kFeX"
      },
      "source": [
        "#%cd /content/SinGAN/ \n",
        "!git checkout experimental\n",
        "![ -d TrainedModels ] && rm -r TrainedModels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Import help functions from SinGAN\n",
        "import config\n",
        "from config import get_arguments\n",
        "from SinGAN.manipulate import *\n",
        "from SinGAN.training import *\n",
        "import SinGAN.functions as functions\n",
        "\n",
        "print('Implement SinGAN here...')\n",
        "\n",
        "# Replace the specific functions we want to reimplement\n",
        "SinGAN.training.train_single_scale = train_single_scale2\n",
        "SinGAN.training.train = train2\n",
        "SinGAN.models.WDiscriminator = WDiscriminator2\n",
        "SinGAN.models.GeneratorConcatSkip2CleanAdd = GeneratorConcatSkip2CleanAdd2\n",
        "functions.read_image = read_image2\n",
        "\n",
        "del sys.argv[:]\n",
        "sys.argv.append('main_train.py')\n",
        "\n",
        "parser = get_arguments()\n",
        "parser.add_argument('--input_dir', help='input image dir', default='Input/Images')\n",
        "parser.add_argument('--input_name', help='input image name', default='LRImage.png')\n",
        "parser.add_argument('--mode', help='task to be done', default='train')\n",
        "\n",
        "opt = parser.parse_args()\n",
        "opt = functions.post_config(opt)\n",
        "\n",
        "Gs = []\n",
        "Zs = []\n",
        "reals = []\n",
        "reals2 = []\n",
        "NoiseAmp = []\n",
        "dir2save = functions.generate_dir2save(opt)\n",
        "\n",
        "if os.path.exists(dir2save):\n",
        "  print('trained model already exists: {}'.format(dir2save))\n",
        "else:\n",
        "  try:\n",
        "    os.makedirs(dir2save)\n",
        "  except OSError:\n",
        "    pass\n",
        "  print(opt)\n",
        "  print(functions.read_image)\n",
        "  #opt.ref_image = ''\n",
        "  opt.input_name = 'HRImage.png'\n",
        "  opt.input_name2 = 'tree_resized.png'\n",
        "  array = functions.read_image(opt)\n",
        "  real = array[0]\n",
        "  real2 = array[1]\n",
        "  #real = functions.read_image(opt)\n",
        "  functions.adjust_scales2image(real, opt)\n",
        "  train2(opt, Gs, Zs, reals, reals2, NoiseAmp)\n",
        "  SinGAN_generate(Gs,Zs,reals,NoiseAmp,opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNaxEk9mKbFT"
      },
      "source": [
        "mkdir /content/SinGAN/Output/RandomSamples/LRImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lef1W2LbbvbX"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxiwGa6zbtIe"
      },
      "source": [
        "#SR.py -> arguments input image dir, training image name, super resolution factor\n",
        "!python3 SR.py --input_name LRImage.png --mode random_samples_arbitrary_sizes --scale_h 1 --scale_v 1\n",
        "!ls\n",
        "!ls -l Output/RandomSamples/HRImage\n",
        "!ls -l Output/RandomSamples/HRImage/gen_start_scale=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzqW9aoqbu46"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print('original image')\n",
        "original_img_path = 'Input/Images/LRImage.png'\n",
        "img = cv2.imread(original_img_path)\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('original image')\n",
        "original_img_path = 'Input/Images/LRImage.png'\n",
        "img = cv2.imread(original_img_path)\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Get generated images\n",
        "img_paths = glob.glob('Output/RandomSamples/HRImage/gen_start_scale=0/*.png')\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[0])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[1])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[2])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[3])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[4])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[5])\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}